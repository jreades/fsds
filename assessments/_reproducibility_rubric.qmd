# Reproducibilty Rubric

To underpin the briefing document (the PDF), and to ensure that your advice can be updated as new information emerges, you will provide a QMD file that demonstrates your ability to produce a transparent, reproducible, and well-documented analytical workflow. It should run from start to finish with minimal intervention and clearly show how your narrative, evidence, and visuals were generated.

Markers will assess the structure, clarity, and reproducibility of your analysis, not the persuasiveness of your argument (which is evaluated in the PDF briefing).

### Marking Rubric

Youâ€™ll be marked on how well your code runs, how clearly it's written, and how easy it is for someone else to reproduce your results.

We'll open your `.qmd` file and test it in the {{< var docker.name >}} container to see if it runs 'end-to-end'.

| Criterion | Weight | What we will look for                                      |
| :----------------- | :------ | :----------------------------------------------------- |
| **Reproducibility & environment** | 35%    | Can your file run smoothly in the provided container? Are dependencies and data handled properly? |
| **Code quality & documentation**  | 30%    | Is your code clean, commented, and easy to follow? |
| **Analytical soundness**          | 25%    | Are your methods appropriate and correctly implemented? |
| **Sustainable Practices**         | 10%    | Does your workflow make effective use of the relevant tools taught this term and their embeddedness in an open source/data context? |

### Tips for Success

- Test your .qmd in a fresh container before submitting.
- Use relative paths and include code to download data automatically.
- Use comments, functions, and other 'tricks' so that we can follow your workflow.
- Commit regularly if using version control and make use of GitHub's collaboration and sharing features.
- Give thought to different aspects of sustainability, including data access/persistence.
