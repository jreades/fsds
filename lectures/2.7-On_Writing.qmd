---
author: "Jon Reades"
email: "j.reades@ucl.ac.uk"
title: "On Writing & Coding"
other: ""
date-as-string: "1st October 2025"
format: revealjs
---

## Writing & Coding == Thinking

> If writing down your ideas always makes them more precise and more complete, then no one who hasn’t written about a topic has fully formed ideas about it. And someone who never writes has no fully formed ideas about anything nontrivial. ~ @graham:2022

&nbsp;

> Writing is thinking. To write well is to think clearly. That’s why it’s so hard. ~ @mccullough:2002

::: {.notes}

A story of struggle. Frustration. Discovery. Learning. But you need to *tell* that story the right way.

Many of you will have learned some 'system' for writing in school. The inverted pyramid or something like that. In university, in my literary *theory* class I picked up the pyramid approach: taking a single sentence and unpacking that into the themes of the entire book.

There are mystery novels. Romance novels. Economist articles. Teen Vogue articles. They are all telling stories. They all do this in different ways.

:::

::: {style="margin-top:0px;"}
# There are *no* shortcuts to thinking and learning.
::: 

## Large Language Models (LLMs)

![](img/OpenAI.png){width=50%}

ChatGPT from OpenAI (an increasingly 'ironic' name) is simply the most famous of a growing number of Large Language Models that draw on information found on the web and in open texts to perform sophisticated summarisation tasks.

## Why Use it for Coding?

Many programmers use LLMs in coding for three reasons:

1. They can help to spot bugs, redundancy, and other issues that impact the performance of large applications (i.e. *feedback*).
2. They can provide information about different libraries and strategies the developer can use, as well as completing code begun by the developer (i.e. *guidance* or *training*).
3. They can help to 'translate' code and design patterns between languages (i.e. *re-use*).

. . . 

These accelerate code production, but there are significant doubts about code quality.

## Why Use it to Learn to Code?

Many students use LLMs to *write* their code for three reasons:

1. They are available at all hours as a personal tutor and advisor.
2. They write better code, more quickly than a learner.
3. They can employ advanced techniques right away.

. . . 

::: {.callout-tip}
### Pro-Tip
Only *one* of these is a good reason.
:::

## Why Use It for Writing?

Many writers use LLMs for three reasons:

1. They can help to ensure consistency and suggest changes in tone or word choice (i.e. *feedback*).
2. They can provide information about different strategies the writer can use to tackle a problem (i.e. *guidance* or *training*).
3. They can help to 'translate' text between languages (i.e. *re-use*).

. . . 

These accelerate word production, but there are significant doubts about quality.

## Why Use it to Learn to Write (Academic English)?

Many students use LLMs to *write* their documents for three reasons:

1. They are available at all hours as a personal tutor and advisor.
2. They write better sentences, more quickly than a learner.
3. They draw on a wider range of sources and styles than a learner.

. . . 

::: {.callout-tip}
### Pro-Tip
Only *one* of these is a good reason.
:::

## Don't Take My Word for It

> Using AI in education is like using a forklift at the gym. The weights do not actually need to be moved from place to place. That is not the work. The work is what happens within you. ~ [Seemingly a conversation on YouTube? ](https://youtu.be/08NuUbcgT9Q?si=jbT_sWOBSDjrKdg4)

::: {.notes}
Excellent! I've always heard students say, "When will I ever use this in real life?" And no teacher ever said, "These classes are not the work. The work is what happens within you." Critical thinking, problem solving, the idea that the world is knowable. That is the work happening with you.

The problem is that many students don't come to uni to learn to write essays, even those that come to learn (not just 'get a degree') often see learning as an accumulation of knowledge rather than the strengthening of a skill. So this gym analogy is really helpful for that too
:::

## Danger, Will Robinson!

Here's what we've noticed about LLM use so far:

::: {.incremental}
- Over-use of flowery language/complex code.
- Over-confidence in recommending solutions.
- Lack of overall structure/coherence.
- Use of non-existent or irrelevant references/coding libraries.
::: 

. . . 

::: {.callout-tip}
### The Underlying Issue
- Lack of actual learning by the student. 
- Undermining of learning by other students. 
- Pointless work by staff.
::: 

::: {.notes}

This is very much a 'brave new world' and we are all trying to figure it out on the fly.

- We think that 'intricate methodologies' and 'exhaustive reviews' aren't just overblown, they actually *invite* you to be marked down because youre methodology or review are not intricate or exhaustive.
- We find individual paragraphs that seem reasonable but the whole doesn't 'work' as a single output.
- One of our PhD students has created a tool to help us find the papers in your bibliography that don't actually exist, or that seem superficially useful but are not relevant in practice.
- Fundamentally, if you're substituting the LLM for thinking then you're not going to learn and that means that you are *not* going to be able to draw the wider connections that mark out strong submissions on assessments and the kind of person that we, or any company, might want to hire!

Basically, they are overconfident and, as a result, tend to either: a) lead the student to think it's not worth the effort of learning (leading the student into deep trouble); or b) lead the student to overconfidence in their self-assessment of submissions or skills (leading the student into deep trouble).

:::


## Read the Fine Print

![](./img/FB_Galactica_Disclaimers.jpg){fig-align="middle" height="65%"}


## We Recommend...

LLMs like ChatGPT *can* help you to learn to be a better coder or writer by providing guidance and feedback, but for many applications a competent human being will be faster and have a better grasp of the *purpose* and *rationale*. 

::: {.callout-warning}

### LLMs as co-authors

Using ChatGPT as your co-*pilot* is not the same as using ChatGPT as your co-*author*. In this module the latter is still considered plagiarism.

:::

::: {.notes}

The people making the *best* use of LLMs are people who already know how to code or write.

:::

## Additional Resources {.smaller}

:::: {.columns}
::: {.column width="50%"}
- [The Myth of the 'Genius Programmer'](https://www.youtube.com/watch?v=0SARbwvhupQ) (by Google Devs)
- ["I mostly had one big, ugly, long, unreadable script"](https://politicalsciencereplication.wordpress.com/2013/08/14/i-mostly-had-one-big-ugly-long-un-readble-script/)
- [Program-Aided Language Models](https://towardsdatascience.com/program-aided-language-models-93d226c7d9a0)
- [Chain of Thought Prompting](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)
- [ChatGPT is a blurry JPEG of the Internet](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) ^[Probably the best 'lay person's' explanation of how LLMs work/fall apart you'll ever read.]
- [Why Meta's latest large language model survived only three days online](https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/) ^[And this one was trained on scientific articles!]
::: 
::: {.column width="50%"}
- [A nice tutorial on distinguishing between plagiarism and paraphrasing](https://libguides.sjsu.edu/plagiarism/home-page).
- Greene, A. E. (2013). *Writing science in plain English*. University of Chicago Press.^[Not seemingly available for free, but I found a nice little summary (with typos) [here](https://thork.people.uic.edu/fair/PlainEnglish.pdf).]
- [Finding your scientific story by writing backwards](https://link.springer.com/article/10.1007/s42995-021-00120-z)
- Sword, H. (2017). *[Air & light & time & space: How successful academics write](https://www.jstor.org/stable/10.2307/j.ctv24w65x8)*. Harvard University Press.^[Available for free via [JStor](https://www.jstor.org/stable/10.2307/j.ctv24w65x8).]
::: 
:::: 

# Thank You {background-image="/img/web/title-slide.png" background-color="#f7eff5" background-opacity="0.2"}

<h3>References</h3>