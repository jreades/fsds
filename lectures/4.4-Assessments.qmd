---
author: "Jon Reades"
email: "j.reades@ucl.ac.uk"
title: "Assessments"
other: ""
date-as-string: "1st October 2025"
format: revealjs
---

## Organise (Your Group)

I am working to allocate everyone to a group of at least four so:

- If you are in a group of less than four you *may* be partnered with students in another practical session to make a 'full strength' group. 
- In this case, you will be reallocated to a mutually convenient practical session so that you are not penalised by being unable to work together.
- I would encourage you to start sitting and working together, and for *one* of you to set up and share a private GitHub repo for Assessment #2 (more on this in a second).

And **remember**: *talk* about how you want your group to work! See: [Group Working](https://jreades.github.io/fsds/sessions/week1.html#class) talk.^[*Note*: In my experience overly narrow specialisation does not work.]

## Assessment #1

#### 1. What is it?

Timed, Open Book Exam

#### 2. What does 'timed' mean?

Once you start the assessment you will have a fixed amount of time in which to complete it; **1h 20m** for most students, but students with relevant SORAs have **2 hours** (please email me).

#### Ok, so when is it?

**{{< var assess.quiz-date >}}**

#### What is the window?

**{{< var assess.quiz-time >}}**^[This is the 'window' for doing the assessment. You can start any time *after* the window opens but must finish *before* the window closes.]

---

#### How do I complete it?

You will access your questions **through Moodle**. You can write the code that you need to *answer* the question in JupyterLab or any other **Python programming environment**. 

#### What does 'open book' mean?

**You may *look*** at any resource you like, **you may not *ask*** another human being for assistance. **You *may* use ChatGPT or another LLM** but must report when you do.

#### What will the exam be on?

Any concept *up to and including Week 5* is 'fair game'. The exam will consist of *no more* than 10 questions.^[So, roughly, that means about 12 minutes/question.] 

---

#### How is it graded?

We will manually grade it in Moodle. There are roughly 960 answers so we may make some mistakes and you can flag these where it is clear this has happened.

#### Why should I report ChatGDP?

The use of ChatGPT has no impact on your grade, we are primarily curious about how useful people are finding it and whether LLMs affect your understanding.

## Assessment #2

The reproducible analysis *must* be a runnable QMD (Quarto Markdown Document) file that addresses the set questions provided in class. The QMD file will be assessed on two components:

1. Its **content** (60% of this assessment): do the answers written by the group engage through a mix of literature, critical thinking, and data analysis with the set questions?
2. Its **reproducibility** (40% of this assessment): do the analyses employed, and outputs created by the group run fully and without errors on a different computer, and do they show evidence of thought in relation to the quality of coding and outputs?

A [template](https://github.com/jreades/fsds/blob/master/assessments/Group_Work.qmd) has been provided. You can see both [PDF](https://jreades.github.io/fsds/assessments/Group_Work.pdf) and [HTML](https://jreades.github.io/fsds/assessments/Group_Work.html) output, but please *only* submit the PDF!

---

### Part 1: Set Questions (60%)

Starting in Week 7, groups will be randomly selected to present their answer to *one* of that week's question *in class*. 

- Formative feedback will be provided *in class* on the quality of the response.
- If the selected group has not prepared an answer then no formative feedback will be provided for that question.

The format is *not* academic: while referencing is still expected, the style for all questions should be written for a *non-specialist* audience. I am updating the rubric to clarify this.

---

### Part 2: Reproducibility (40%)

Your QMD document will be evaluated *separately* from its content for:

1. *Reproducibility* (20%) — Can the analysis be run on another system? Two considerations: 1) without changes to the code; and 2) with useful guidance/documentation being offered in terms of what to do if ‘things go wrong’.
2. *Quality* (20%) — Is the code/analysis intelligible and well-presented such that another user doesn’t just ‘run the code’ but actually understands and has confidence in the how and why of what you've done? This is about making maximal use of the tools at their disposal such that the code is efficient, even elegant, and the outputs are clear and legible.

## Assessment #3

We know that people contribute differently to groups or, sometimes, not at all. This self- and peer-assessment seeks to quantify that contribution while also prompting you to reflect on what *you* contributed to your group. 

# Questions? {background-image="/img/web/title-slide.png" background-color="#f7eff5" background-opacity="0.2"}

<h3>References</h3>
